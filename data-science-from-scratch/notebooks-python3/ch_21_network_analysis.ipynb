{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betweenness Centrality\n",
      "0 0.0\n",
      "1 3.5\n",
      "2 3.5\n",
      "3 18.0\n",
      "4 20.0\n",
      "5 20.5\n",
      "6 6.0\n",
      "7 6.0\n",
      "8 8.5\n",
      "9 0.0\n",
      "\n",
      "Closeness Centrality\n",
      "0 0.029411764705882353\n",
      "1 0.037037037037037035\n",
      "2 0.037037037037037035\n",
      "3 0.045454545454545456\n",
      "4 0.05\n",
      "5 0.05\n",
      "6 0.041666666666666664\n",
      "7 0.041666666666666664\n",
      "8 0.03571428571428571\n",
      "9 0.027777777777777776\n",
      "\n",
      "Eigenvector Centrality\n",
      "0 0.38578006614957344\n",
      "1 0.5147902322356226\n",
      "2 0.5147902322356226\n",
      "3 0.47331220396377677\n",
      "4 0.23361029944966002\n",
      "5 0.1501458150031844\n",
      "6 0.08355561051056493\n",
      "7 0.08355561051056493\n",
      "8 0.07284034177922594\n",
      "9 0.027294660139652423\n",
      "\n",
      "PageRank\n",
      "0 0.0404553415061296\n",
      "1 0.044921190893169885\n",
      "2 0.044921190893169885\n",
      "3 0.0404553415061296\n",
      "4 0.06785083675770529\n",
      "5 0.04344422700587085\n",
      "6 0.03346379647749512\n",
      "7 0.03346379647749512\n",
      "8 0.04344422700587085\n",
      "9 0.03346379647749512\n"
     ]
    }
   ],
   "source": [
    "import math, random, re\n",
    "from collections import defaultdict, Counter, deque\n",
    "from linear_algebra import dot, get_row, get_column, make_matrix, magnitude, scalar_multiply, shape, distance\n",
    "from functools import partial\n",
    "\n",
    "users = [\n",
    "    { \"id\": 0, \"name\": \"Hero\" },\n",
    "    { \"id\": 1, \"name\": \"Dunn\" },\n",
    "    { \"id\": 2, \"name\": \"Sue\" },\n",
    "    { \"id\": 3, \"name\": \"Chi\" },\n",
    "    { \"id\": 4, \"name\": \"Thor\" },\n",
    "    { \"id\": 5, \"name\": \"Clive\" },\n",
    "    { \"id\": 6, \"name\": \"Hicks\" },\n",
    "    { \"id\": 7, \"name\": \"Devin\" },\n",
    "    { \"id\": 8, \"name\": \"Kate\" },\n",
    "    { \"id\": 9, \"name\": \"Klein\" }\n",
    "]\n",
    "\n",
    "friendships = [(0, 1), (0, 2), (1, 2), (1, 3), (2, 3), (3, 4),\n",
    "               (4, 5), (5, 6), (5, 7), (6, 8), (7, 8), (8, 9)]\n",
    "\n",
    "# give each user a friends list\n",
    "for user in users:\n",
    "    user[\"friends\"] = []\n",
    "\n",
    "# and populate it\n",
    "for i, j in friendships:\n",
    "    # this works because users[i] is the user whose id is i\n",
    "    users[i][\"friends\"].append(users[j]) # add i as a friend of j\n",
    "    users[j][\"friends\"].append(users[i]) # add j as a friend of i\n",
    "\n",
    "#\n",
    "# Betweenness Centrality\n",
    "#\n",
    "\n",
    "def shortest_paths_from(from_user):\n",
    "\n",
    "    # a dictionary from \"user_id\" to *all* shortest paths to that user\n",
    "    shortest_paths_to = { from_user[\"id\"] : [[]] }\n",
    "\n",
    "    # a queue of (previous user, next user) that we need to check.\n",
    "    # starts out with all pairs (from_user, friend_of_from_user)\n",
    "    frontier = deque((from_user, friend)\n",
    "                     for friend in from_user[\"friends\"])\n",
    "\n",
    "    # keep going until we empty the queue\n",
    "    while frontier:\n",
    "\n",
    "        prev_user, user = frontier.popleft() # take from the beginning\n",
    "        user_id = user[\"id\"]\n",
    "\n",
    "        # the fact that we're pulling from our queue means that\n",
    "        # necessarily we already know a shortest path to prev_user\n",
    "        paths_to_prev = shortest_paths_to[prev_user[\"id\"]]\n",
    "        paths_via_prev = [path + [user_id] for path in paths_to_prev]\n",
    "\n",
    "        # it's possible we already know a shortest path to here as well\n",
    "        old_paths_to_here = shortest_paths_to.get(user_id, [])\n",
    "\n",
    "        # what's the shortest path to here that we've seen so far?\n",
    "        if old_paths_to_here:\n",
    "            min_path_length = len(old_paths_to_here[0])\n",
    "        else:\n",
    "            min_path_length = float('inf')\n",
    "\n",
    "        # any new paths to here that aren't too long\n",
    "        new_paths_to_here = [path_via_prev\n",
    "                             for path_via_prev in paths_via_prev\n",
    "                             if len(path_via_prev) <= min_path_length\n",
    "                             and path_via_prev not in old_paths_to_here]\n",
    "\n",
    "        shortest_paths_to[user_id] = old_paths_to_here + new_paths_to_here\n",
    "\n",
    "        # add new neighbors to the frontier\n",
    "        frontier.extend((user, friend)\n",
    "                        for friend in user[\"friends\"]\n",
    "                        if friend[\"id\"] not in shortest_paths_to)\n",
    "\n",
    "    return shortest_paths_to\n",
    "\n",
    "for user in users:\n",
    "    user[\"shortest_paths\"] = shortest_paths_from(user)\n",
    "\n",
    "for user in users:\n",
    "    user[\"betweenness_centrality\"] = 0.0\n",
    "\n",
    "for source in users:\n",
    "    source_id = source[\"id\"]\n",
    "    for target_id, paths in source[\"shortest_paths\"].items():\n",
    "        if source_id < target_id:   # don't double count\n",
    "            num_paths = len(paths)  # how many shortest paths?\n",
    "            contrib = 1 / num_paths # contribution to centrality\n",
    "            for path in paths:\n",
    "                for id in path:\n",
    "                    if id not in [source_id, target_id]:\n",
    "                        users[id][\"betweenness_centrality\"] += contrib\n",
    "\n",
    "#\n",
    "# closeness centrality\n",
    "#\n",
    "\n",
    "def farness(user):\n",
    "    \"\"\"the sum of the lengths of the shortest paths to each other user\"\"\"\n",
    "    return sum(len(paths[0])\n",
    "               for paths in user[\"shortest_paths\"].values())\n",
    "\n",
    "for user in users:\n",
    "    user[\"closeness_centrality\"] = 1 / farness(user)\n",
    "\n",
    "\n",
    "#\n",
    "# matrix multiplication\n",
    "#\n",
    "\n",
    "def matrix_product_entry(A, B, i, j):\n",
    "    return dot(get_row(A, i), get_column(B, j))\n",
    "\n",
    "def matrix_multiply(A, B):\n",
    "    n1, k1 = shape(A)\n",
    "    n2, k2 = shape(B)\n",
    "    if k1 != n2:\n",
    "        raise ArithmeticError(\"incompatible shapes!\")\n",
    "\n",
    "    return make_matrix(n1, k2, partial(matrix_product_entry, A, B))\n",
    "\n",
    "def vector_as_matrix(v):\n",
    "    \"\"\"returns the vector v (represented as a list) as a n x 1 matrix\"\"\"\n",
    "    return [[v_i] for v_i in v]\n",
    "\n",
    "def vector_from_matrix(v_as_matrix):\n",
    "    \"\"\"returns the n x 1 matrix as a list of values\"\"\"\n",
    "    return [row[0] for row in v_as_matrix]\n",
    "\n",
    "def matrix_operate(A, v):\n",
    "    v_as_matrix = vector_as_matrix(v)\n",
    "    product = matrix_multiply(A, v_as_matrix)\n",
    "    return vector_from_matrix(product)\n",
    "\n",
    "def find_eigenvector(A, tolerance=0.00001):\n",
    "    guess = [1 for __ in A]\n",
    "\n",
    "    while True:\n",
    "        result = matrix_operate(A, guess)\n",
    "        length = magnitude(result)\n",
    "        next_guess = scalar_multiply(1/length, result)\n",
    "\n",
    "        if distance(guess, next_guess) < tolerance:\n",
    "            return next_guess, length # eigenvector, eigenvalue\n",
    "\n",
    "        guess = next_guess\n",
    "\n",
    "#\n",
    "# eigenvector centrality\n",
    "#\n",
    "\n",
    "def entry_fn(i, j):\n",
    "    return 1 if (i, j) in friendships or (j, i) in friendships else 0\n",
    "\n",
    "n = len(users)\n",
    "adjacency_matrix = make_matrix(n, n, entry_fn)\n",
    "\n",
    "eigenvector_centralities, _ = find_eigenvector(adjacency_matrix)\n",
    "\n",
    "#\n",
    "# directed graphs\n",
    "#\n",
    "\n",
    "endorsements = [(0, 1), (1, 0), (0, 2), (2, 0), (1, 2), (2, 1), (1, 3),\n",
    "                (2, 3), (3, 4), (5, 4), (5, 6), (7, 5), (6, 8), (8, 7), (8, 9)]\n",
    "\n",
    "for user in users:\n",
    "    user[\"endorses\"] = []       # add one list to track outgoing endorsements\n",
    "    user[\"endorsed_by\"] = []    # and another to track endorsements\n",
    "\n",
    "for source_id, target_id in endorsements:\n",
    "    users[source_id][\"endorses\"].append(users[target_id])\n",
    "    users[target_id][\"endorsed_by\"].append(users[source_id])\n",
    "\n",
    "\n",
    "endorsements_by_id = [(user[\"id\"], len(user[\"endorsed_by\"]))\n",
    "                      for user in users]\n",
    "\n",
    "sorted(endorsements_by_id,\n",
    "       key=lambda pair: pair[1],\n",
    "       reverse=True)\n",
    "\n",
    "def page_rank(users, damping = 0.85, num_iters = 100):\n",
    "\n",
    "    # initially distribute PageRank evenly\n",
    "    num_users = len(users)\n",
    "    pr = { user[\"id\"] : 1 / num_users for user in users }\n",
    "\n",
    "    # this is the small fraction of PageRank\n",
    "    # that each node gets each iteration\n",
    "    base_pr = (1 - damping) / num_users\n",
    "\n",
    "    for __ in range(num_iters):\n",
    "        next_pr = { user[\"id\"] : base_pr for user in users }\n",
    "        for user in users:\n",
    "            # distribute PageRank to outgoing links\n",
    "            links_pr = pr[user[\"id\"]] * damping\n",
    "            for endorsee in user[\"endorses\"]:\n",
    "                next_pr[endorsee[\"id\"]] += links_pr / len(user[\"endorses\"])\n",
    "\n",
    "        pr = next_pr\n",
    "\n",
    "    return pr\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"Betweenness Centrality\")\n",
    "    for user in users:\n",
    "        print(user[\"id\"], user[\"betweenness_centrality\"])\n",
    "    print()\n",
    "\n",
    "    print(\"Closeness Centrality\")\n",
    "    for user in users:\n",
    "        print(user[\"id\"], user[\"closeness_centrality\"])\n",
    "    print()\n",
    "\n",
    "    print(\"Eigenvector Centrality\")\n",
    "    for user_id, centrality in enumerate(eigenvector_centralities):\n",
    "        print(user_id, centrality)\n",
    "    print()\n",
    "\n",
    "    print(\"PageRank\")\n",
    "    for user_id, pr in page_rank(users).items():\n",
    "        print(user_id, pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
