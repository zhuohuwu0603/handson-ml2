{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation(xs, ys1) 0.9020393512972853\n",
      "correlation(xs, ys2) -0.9011135591672421\n",
      "[datetime.datetime(2014, 6, 19, 0, 0), 'MSFT', None]\n",
      "stocks\n",
      "max aapl price 119.0\n",
      "max price by symbol\n",
      "{'AAPL': 119.0, 'MSFT': 49.3, 'FB': 81.45}\n",
      "max change {'symbol': 'AAPL', 'change': 0.3283582089552237, 'date': datetime.datetime(1997, 8, 6, 0, 0)}\n",
      "min change {'symbol': 'AAPL', 'change': -0.5193370165745856, 'date': datetime.datetime(2000, 9, 29, 0, 0)}\n",
      "overall change by month\n",
      "{1: 19.972214514609085, 2: 0.11858483359215, 3: 2.818850048603327, 4: 6.9341967849847626, 5: 1.2555660890321603, 6: -0.5977889232201744, 7: -0.17183091713561482, 8: 6.220055959879489, 9: -0.741162543642831, 10: 21.552541251680015, 11: 3.758572336791725, 12: 2.2895332950255933}\n",
      "rescaling\n",
      "original:  [[1, 20, 2], [1, 30, 3], [1, 40, 4]]\n",
      "scale:  ([1.0, 30.0, 3.0], [0.0, 10.0, 1.0])\n",
      "rescaled:  [[1, -1.0, -1.0], [1, 0.0, 0.0], [1, 1.0, 1.0]]\n",
      "\n",
      "PCA\n",
      "principal components [[0.9238554090431896, 0.382741666377781], [-0.3827224539579983, 0.9238633682728025]]\n",
      "first point [0.6663708720254604, 1.6869418499129427]\n",
      "first point transformed [1.2612932692676448, 1.3034686841532082]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from functools import partial, reduce\n",
    "from linear_algebra import shape, get_row, get_column, make_matrix, \\\n",
    "    vector_mean, vector_sum, dot, magnitude, vector_subtract, scalar_multiply\n",
    "from stats import correlation, standard_deviation, mean\n",
    "from probability import inverse_normal_cdf\n",
    "from gradient_descent import maximize_batch\n",
    "import math, random, csv\n",
    "import matplotlib.pyplot as plt\n",
    "import dateutil.parser\n",
    "\n",
    "def bucketize(point, bucket_size):\n",
    "    \"\"\"floor the point to the next lower multiple of bucket_size\"\"\"\n",
    "    return bucket_size * math.floor(point / bucket_size)\n",
    "\n",
    "def make_histogram(points, bucket_size):\n",
    "    \"\"\"buckets the points and counts how many in each bucket\"\"\"\n",
    "    return Counter(bucketize(point, bucket_size) for point in points)\n",
    "\n",
    "def plot_histogram(points, bucket_size, title=\"\"):\n",
    "    histogram = make_histogram(points, bucket_size)\n",
    "    plt.bar(histogram.keys(), histogram.values(), width=bucket_size)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def compare_two_distributions():\n",
    "\n",
    "    random.seed(0)\n",
    "\n",
    "    uniform = [random.randrange(-100,101) for _ in range(200)]\n",
    "    normal = [57 * inverse_normal_cdf(random.random())\n",
    "              for _ in range(200)]\n",
    "\n",
    "    plot_histogram(uniform, 10, \"Uniform Histogram\")\n",
    "    plot_histogram(normal, 10, \"Normal Histogram\")\n",
    "\n",
    "def random_normal():\n",
    "    \"\"\"returns a random draw from a standard normal distribution\"\"\"\n",
    "    return inverse_normal_cdf(random.random())\n",
    "\n",
    "xs = [random_normal() for _ in range(1000)]\n",
    "ys1 = [ x + random_normal() / 2 for x in xs]\n",
    "ys2 = [-x + random_normal() / 2 for x in xs]\n",
    "\n",
    "\n",
    "def scatter():\n",
    "    plt.scatter(xs, ys1, marker='.', color='black', label='ys1')\n",
    "    plt.scatter(xs, ys2, marker='.', color='gray',  label='ys2')\n",
    "    plt.xlabel('xs')\n",
    "    plt.ylabel('ys')\n",
    "    plt.legend(loc=9)\n",
    "    plt.show()\n",
    "\n",
    "def correlation_matrix(data):\n",
    "    \"\"\"returns the num_columns x num_columns matrix whose (i, j)th entry\n",
    "    is the correlation between columns i and j of data\"\"\"\n",
    "\n",
    "    _, num_columns = shape(data)\n",
    "\n",
    "    def matrix_entry(i, j):\n",
    "        return correlation(get_column(data, i), get_column(data, j))\n",
    "\n",
    "    return make_matrix(num_columns, num_columns, matrix_entry)\n",
    "\n",
    "def make_scatterplot_matrix():\n",
    "\n",
    "    # first, generate some random data\n",
    "\n",
    "    num_points = 100\n",
    "\n",
    "    def random_row():\n",
    "        row = [None, None, None, None]\n",
    "        row[0] = random_normal()\n",
    "        row[1] = -5 * row[0] + random_normal()\n",
    "        row[2] = row[0] + row[1] + 5 * random_normal()\n",
    "        row[3] = 6 if row[2] > -2 else 0\n",
    "        return row\n",
    "    random.seed(0)\n",
    "    data = [random_row()\n",
    "            for _ in range(num_points)]\n",
    "\n",
    "    # then plot it\n",
    "\n",
    "    _, num_columns = shape(data)\n",
    "    fig, ax = plt.subplots(num_columns, num_columns)\n",
    "\n",
    "    for i in range(num_columns):\n",
    "        for j in range(num_columns):\n",
    "\n",
    "            # scatter column_j on the x-axis vs column_i on the y-axis\n",
    "            if i != j: ax[i][j].scatter(get_column(data, j), get_column(data, i))\n",
    "\n",
    "            # unless i == j, in which case show the series name\n",
    "            else: ax[i][j].annotate(\"series \" + str(i), (0.5, 0.5),\n",
    "                                    xycoords='axes fraction',\n",
    "                                    ha=\"center\", va=\"center\")\n",
    "\n",
    "            # then hide axis labels except left and bottom charts\n",
    "            if i < num_columns - 1: ax[i][j].xaxis.set_visible(False)\n",
    "            if j > 0: ax[i][j].yaxis.set_visible(False)\n",
    "\n",
    "    # fix the bottom right and top left axis labels, which are wrong because\n",
    "    # their charts only have text in them\n",
    "    ax[-1][-1].set_xlim(ax[0][-1].get_xlim())\n",
    "    ax[0][0].set_ylim(ax[0][1].get_ylim())\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def parse_row(input_row, parsers):\n",
    "    \"\"\"given a list of parsers (some of which may be None)\n",
    "    apply the appropriate one to each element of the input_row\"\"\"\n",
    "    return [parser(value) if parser is not None else value\n",
    "            for value, parser in zip(input_row, parsers)]\n",
    "\n",
    "def parse_rows_with(reader, parsers):\n",
    "    \"\"\"wrap a reader to apply the parsers to each of its rows\"\"\"\n",
    "    for row in reader:\n",
    "        yield parse_row(row, parsers)\n",
    "\n",
    "def try_or_none(f):\n",
    "    \"\"\"wraps f to return None if f raises an exception\n",
    "    assumes f takes only one input\"\"\"\n",
    "    def f_or_none(x):\n",
    "        try: return f(x)\n",
    "        except: return None\n",
    "    return f_or_none\n",
    "\n",
    "def parse_row(input_row, parsers):\n",
    "    return [try_or_none(parser)(value) if parser is not None else value\n",
    "            for value, parser in zip(input_row, parsers)]\n",
    "\n",
    "def try_parse_field(field_name, value, parser_dict):\n",
    "    \"\"\"try to parse value using the appropriate function from parser_dict\"\"\"\n",
    "    parser = parser_dict.get(field_name) # None if no such entry\n",
    "    if parser is not None:\n",
    "        return try_or_none(parser)(value)\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "def parse_dict(input_dict, parser_dict):\n",
    "    return { field_name : try_parse_field(field_name, value, parser_dict)\n",
    "             for field_name, value in input_dict.items() }\n",
    "\n",
    "#\n",
    "#\n",
    "# MANIPULATING DATA\n",
    "#\n",
    "#\n",
    "\n",
    "def picker(field_name):\n",
    "    \"\"\"returns a function that picks a field out of a dict\"\"\"\n",
    "    return lambda row: row[field_name]\n",
    "\n",
    "def pluck(field_name, rows):\n",
    "    \"\"\"turn a list of dicts into the list of field_name values\"\"\"\n",
    "    return map(picker(field_name), rows)\n",
    "\n",
    "def group_by(grouper, rows, value_transform=None):\n",
    "    # key is output of grouper, value is list of rows\n",
    "    grouped = defaultdict(list)\n",
    "    for row in rows:\n",
    "        grouped[grouper(row)].append(row)\n",
    "    if value_transform is None:\n",
    "        return grouped\n",
    "    else:\n",
    "        return { key : value_transform(rows)\n",
    "                 for key, rows in grouped.items() }\n",
    "\n",
    "def percent_price_change(yesterday, today):\n",
    "    return today[\"closing_price\"] / yesterday[\"closing_price\"] - 1\n",
    "\n",
    "def day_over_day_changes(grouped_rows):\n",
    "    # sort the rows by date\n",
    "    ordered = sorted(grouped_rows, key=picker(\"date\"))\n",
    "    # zip with an offset to get pairs of consecutive days\n",
    "    return [{ \"symbol\" : today[\"symbol\"],\n",
    "              \"date\" : today[\"date\"],\n",
    "              \"change\" : percent_price_change(yesterday, today) }\n",
    "             for yesterday, today in zip(ordered, ordered[1:])]\n",
    "\n",
    "#\n",
    "#\n",
    "# RESCALING DATA\n",
    "#\n",
    "#\n",
    "\n",
    "def scale(data_matrix):\n",
    "    num_rows, num_cols = shape(data_matrix)\n",
    "    means = [mean(get_column(data_matrix,j))\n",
    "             for j in range(num_cols)]\n",
    "    stdevs = [standard_deviation(get_column(data_matrix,j))\n",
    "              for j in range(num_cols)]\n",
    "    return means, stdevs\n",
    "\n",
    "def rescale(data_matrix):\n",
    "    \"\"\"rescales the input data so that each column\n",
    "    has mean 0 and standard deviation 1\n",
    "    ignores columns with no deviation\"\"\"\n",
    "    means, stdevs = scale(data_matrix)\n",
    "\n",
    "    def rescaled(i, j):\n",
    "        if stdevs[j] > 0:\n",
    "            return (data_matrix[i][j] - means[j]) / stdevs[j]\n",
    "        else:\n",
    "            return data_matrix[i][j]\n",
    "\n",
    "    num_rows, num_cols = shape(data_matrix)\n",
    "    return make_matrix(num_rows, num_cols, rescaled)\n",
    "\n",
    "#\n",
    "# DIMENSIONALITY REDUCTION\n",
    "#\n",
    "\n",
    "X = [\n",
    "    [20.9666776351559,-13.1138080189357],\n",
    "    [22.7719907680008,-19.8890894944696],\n",
    "    [25.6687103160153,-11.9956004517219],\n",
    "    [18.0019794950564,-18.1989191165133],\n",
    "    [21.3967402102156,-10.8893126308196],\n",
    "    [0.443696899177716,-19.7221132386308],\n",
    "    [29.9198322142127,-14.0958668502427],\n",
    "    [19.0805843080126,-13.7888747608312],\n",
    "    [16.4685063521314,-11.2612927034291],\n",
    "    [21.4597664701884,-12.4740034586705],\n",
    "    [3.87655283720532,-17.575162461771],\n",
    "    [34.5713920556787,-10.705185165378],\n",
    "    [13.3732115747722,-16.7270274494424],\n",
    "    [20.7281704141919,-8.81165591556553],\n",
    "    [24.839851437942,-12.1240962157419],\n",
    "    [20.3019544741252,-12.8725060780898],\n",
    "    [21.9021426929599,-17.3225432396452],\n",
    "    [23.2285885715486,-12.2676568419045],\n",
    "    [28.5749111681851,-13.2616470619453],\n",
    "    [29.2957424128701,-14.6299928678996],\n",
    "    [15.2495527798625,-18.4649714274207],\n",
    "    [26.5567257400476,-9.19794350561966],\n",
    "    [30.1934232346361,-12.6272709845971],\n",
    "    [36.8267446011057,-7.25409849336718],\n",
    "    [32.157416823084,-10.4729534347553],\n",
    "    [5.85964365291694,-22.6573731626132],\n",
    "    [25.7426190674693,-14.8055803854566],\n",
    "    [16.237602636139,-16.5920595763719],\n",
    "    [14.7408608850568,-20.0537715298403],\n",
    "    [6.85907008242544,-18.3965586884781],\n",
    "    [26.5918329233128,-8.92664811750842],\n",
    "    [-11.2216019958228,-27.0519081982856],\n",
    "    [8.93593745011035,-20.8261235122575],\n",
    "    [24.4481258671796,-18.0324012215159],\n",
    "    [2.82048515404903,-22.4208457598703],\n",
    "    [30.8803004755948,-11.455358009593],\n",
    "    [15.4586738236098,-11.1242825084309],\n",
    "    [28.5332537090494,-14.7898744423126],\n",
    "    [40.4830293441052,-2.41946428697183],\n",
    "    [15.7563759125684,-13.5771266003795],\n",
    "    [19.3635588851727,-20.6224770470434],\n",
    "    [13.4212840786467,-19.0238227375766],\n",
    "    [7.77570680426702,-16.6385739839089],\n",
    "    [21.4865983854408,-15.290799330002],\n",
    "    [12.6392705930724,-23.6433305964301],\n",
    "    [12.4746151388128,-17.9720169566614],\n",
    "    [23.4572410437998,-14.602080545086],\n",
    "    [13.6878189833565,-18.9687408182414],\n",
    "    [15.4077465943441,-14.5352487124086],\n",
    "    [20.3356581548895,-10.0883159703702],\n",
    "    [20.7093833689359,-12.6939091236766],\n",
    "    [11.1032293684441,-14.1383848928755],\n",
    "    [17.5048321498308,-9.2338593361801],\n",
    "    [16.3303688220188,-15.1054735529158],\n",
    "    [26.6929062710726,-13.306030567991],\n",
    "    [34.4985678099711,-9.86199941278607],\n",
    "    [39.1374291499406,-10.5621430853401],\n",
    "    [21.9088956482146,-9.95198845621849],\n",
    "    [22.2367457578087,-17.2200123442707],\n",
    "    [10.0032784145577,-19.3557700653426],\n",
    "    [14.045833906665,-15.871937521131],\n",
    "    [15.5640911917607,-18.3396956121887],\n",
    "    [24.4771926581586,-14.8715313479137],\n",
    "    [26.533415556629,-14.693883922494],\n",
    "    [12.8722580202544,-21.2750596021509],\n",
    "    [24.4768291376862,-15.9592080959207],\n",
    "    [18.2230748567433,-14.6541444069985],\n",
    "    [4.1902148367447,-20.6144032528762],\n",
    "    [12.4332594022086,-16.6079789231489],\n",
    "    [20.5483758651873,-18.8512560786321],\n",
    "    [17.8180560451358,-12.5451990696752],\n",
    "    [11.0071081078049,-20.3938092335862],\n",
    "    [8.30560561422449,-22.9503944138682],\n",
    "    [33.9857852657284,-4.8371294974382],\n",
    "    [17.4376502239652,-14.5095976075022],\n",
    "    [29.0379635148943,-14.8461553663227],\n",
    "    [29.1344666599319,-7.70862921632672],\n",
    "    [32.9730697624544,-15.5839178785654],\n",
    "    [13.4211493998212,-20.150199857584],\n",
    "    [11.380538260355,-12.8619410359766],\n",
    "    [28.672631499186,-8.51866271785711],\n",
    "    [16.4296061111902,-23.3326051279759],\n",
    "    [25.7168371582585,-13.8899296143829],\n",
    "    [13.3185154732595,-17.8959160024249],\n",
    "    [3.60832478605376,-25.4023343597712],\n",
    "    [39.5445949652652,-11.466377647931],\n",
    "    [25.1693484426101,-12.2752652925707],\n",
    "    [25.2884257196471,-7.06710309184533],\n",
    "    [6.77665715793125,-22.3947299635571],\n",
    "    [20.1844223778907,-16.0427471125407],\n",
    "    [25.5506805272535,-9.33856532270204],\n",
    "    [25.1495682602477,-7.17350567090738],\n",
    "    [15.6978431006492,-17.5979197162642],\n",
    "    [37.42780451491,-10.843637288504],\n",
    "    [22.974620174842,-10.6171162611686],\n",
    "    [34.6327117468934,-9.26182440487384],\n",
    "    [34.7042513789061,-6.9630753351114],\n",
    "    [15.6563953929008,-17.2196961218915],\n",
    "    [25.2049825789225,-14.1592086208169]\n",
    "]\n",
    "\n",
    "def de_mean_matrix(A):\n",
    "    \"\"\"returns the result of subtracting from every value in A the mean\n",
    "    value of its column. the resulting matrix has mean 0 in every column\"\"\"\n",
    "    nr, nc = shape(A)\n",
    "    column_means, _ = scale(A)\n",
    "    return make_matrix(nr, nc, lambda i, j: A[i][j] - column_means[j])\n",
    "\n",
    "def direction(w):\n",
    "    mag = magnitude(w)\n",
    "    return [w_i / mag for w_i in w]\n",
    "\n",
    "def directional_variance_i(x_i, w):\n",
    "    \"\"\"the variance of the row x_i in the direction w\"\"\"\n",
    "    return dot(x_i, direction(w)) ** 2\n",
    "\n",
    "def directional_variance(X, w):\n",
    "    \"\"\"the variance of the data in the direction w\"\"\"\n",
    "    return sum(directional_variance_i(x_i, w) for x_i in X)\n",
    "\n",
    "def directional_variance_gradient_i(x_i, w):\n",
    "    \"\"\"the contribution of row x_i to the gradient of\n",
    "    the direction-w variance\"\"\"\n",
    "    projection_length = dot(x_i, direction(w))\n",
    "    return [2 * projection_length * x_ij for x_ij in x_i]\n",
    "\n",
    "def directional_variance_gradient(X, w):\n",
    "    return vector_sum(directional_variance_gradient_i(x_i,w) for x_i in X)\n",
    "\n",
    "def first_principal_component(X):\n",
    "    guess = [1 for _ in X[0]]\n",
    "    unscaled_maximizer = maximize_batch(\n",
    "        partial(directional_variance, X),           # is now a function of w\n",
    "        partial(directional_variance_gradient, X),  # is now a function of w\n",
    "        guess)\n",
    "    return direction(unscaled_maximizer)\n",
    "\n",
    "def first_principal_component_sgd(X):\n",
    "    guess = [1 for _ in X[0]]\n",
    "    unscaled_maximizer = maximize_stochastic(\n",
    "        lambda x, _, w: directional_variance_i(x, w),\n",
    "        lambda x, _, w: directional_variance_gradient_i(x, w),\n",
    "        X, [None for _ in X], guess)\n",
    "    return direction(unscaled_maximizer)\n",
    "\n",
    "def project(v, w):\n",
    "    \"\"\"return the projection of v onto w\"\"\"\n",
    "    coefficient = dot(v, w)\n",
    "    return scalar_multiply(coefficient, w)\n",
    "\n",
    "def remove_projection_from_vector(v, w):\n",
    "    \"\"\"projects v onto w and subtracts the result from v\"\"\"\n",
    "    return vector_subtract(v, project(v, w))\n",
    "\n",
    "def remove_projection(X, w):\n",
    "    \"\"\"for each row of X\n",
    "    projects the row onto w, and subtracts the result from the row\"\"\"\n",
    "    return [remove_projection_from_vector(x_i, w) for x_i in X]\n",
    "\n",
    "def principal_component_analysis(X, num_components):\n",
    "    components = []\n",
    "    for _ in range(num_components):\n",
    "        component = first_principal_component(X)\n",
    "        components.append(component)\n",
    "        X = remove_projection(X, component)\n",
    "\n",
    "    return components\n",
    "\n",
    "def transform_vector(v, components):\n",
    "    return [dot(v, w) for w in components]\n",
    "\n",
    "def transform(X, components):\n",
    "    return [transform_vector(x_i, components) for x_i in X]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"correlation(xs, ys1)\", correlation(xs, ys1))\n",
    "    print(\"correlation(xs, ys2)\", correlation(xs, ys2))\n",
    "\n",
    "    # safe parsing\n",
    "\n",
    "    data = []\n",
    "\n",
    "    with open(\"comma_delimited_stock_prices.csv\", \"r\", encoding='utf8', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for line in parse_rows_with(reader, [dateutil.parser.parse, None, float]):\n",
    "            data.append(line)\n",
    "\n",
    "    for row in data:\n",
    "        if any(x is None for x in row):\n",
    "            print(row)\n",
    "\n",
    "    print(\"stocks\")\n",
    "    with open(\"stocks.txt\", \"r\", encoding='utf8', newline='') as f:\n",
    "        reader = csv.DictReader(f, delimiter=\"\\t\")\n",
    "        data = [parse_dict(row, { 'date' : dateutil.parser.parse,\n",
    "                                  'closing_price' : float })\n",
    "                for row in reader]\n",
    "\n",
    "    max_aapl_price = max(row[\"closing_price\"]\n",
    "                         for row in data\n",
    "                         if row[\"symbol\"] == \"AAPL\")\n",
    "    print(\"max aapl price\", max_aapl_price)\n",
    "\n",
    "    # group rows by symbol\n",
    "    by_symbol = defaultdict(list)\n",
    "\n",
    "    for row in data:\n",
    "        by_symbol[row[\"symbol\"]].append(row)\n",
    "\n",
    "    # use a dict comprehension to find the max for each symbol\n",
    "    max_price_by_symbol = { symbol : max(row[\"closing_price\"]\n",
    "                            for row in grouped_rows)\n",
    "                            for symbol, grouped_rows in by_symbol.items() }\n",
    "    print(\"max price by symbol\")\n",
    "    print(max_price_by_symbol)\n",
    "\n",
    "    # key is symbol, value is list of \"change\" dicts\n",
    "    changes_by_symbol = group_by(picker(\"symbol\"), data, day_over_day_changes)\n",
    "    # collect all \"change\" dicts into one big list\n",
    "    all_changes = [change\n",
    "                   for changes in changes_by_symbol.values()\n",
    "                   for change in changes]\n",
    "\n",
    "    print(\"max change\", max(all_changes, key=picker(\"change\")))\n",
    "    print(\"min change\", min(all_changes, key=picker(\"change\")))\n",
    "\n",
    "    # to combine percent changes, we add 1 to each, multiply them, and subtract 1\n",
    "    # for instance, if we combine +10% and -20%, the overall change is\n",
    "    # (1 + 10%) * (1 - 20%) - 1 = 1.1 * .8 - 1 = -12%\n",
    "    def combine_pct_changes(pct_change1, pct_change2):\n",
    "        return (1 + pct_change1) * (1 + pct_change2) - 1\n",
    "\n",
    "    def overall_change(changes):\n",
    "        return reduce(combine_pct_changes, pluck(\"change\", changes))\n",
    "\n",
    "    overall_change_by_month = group_by(lambda row: row['date'].month,\n",
    "                                       all_changes,\n",
    "                                       overall_change)\n",
    "    print(\"overall change by month\")\n",
    "    print(overall_change_by_month)\n",
    "\n",
    "    print(\"rescaling\")\n",
    "\n",
    "    data = [[1, 20, 2],\n",
    "            [1, 30, 3],\n",
    "            [1, 40, 4]]\n",
    "\n",
    "    print(\"original: \", data)\n",
    "    print(\"scale: \", scale(data))\n",
    "    print(\"rescaled: \", rescale(data))\n",
    "    print()\n",
    "\n",
    "    print(\"PCA\")\n",
    "\n",
    "    Y = de_mean_matrix(X)\n",
    "    components = principal_component_analysis(Y, 2)\n",
    "    print(\"principal components\", components)\n",
    "    print(\"first point\", Y[0])\n",
    "    print(\"first point transformed\", transform_vector(Y[0], components))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
