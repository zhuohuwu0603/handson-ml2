{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "**Module 8: Kaggle Data Sets**\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8 Material\n",
    "\n",
    "* Part 8.1: Introduction to Kaggle [[Video]](https://www.youtube.com/watch?v=v4lJBhdCuCU&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](t81_558_class_08_1_kaggle_intro.ipynb)\n",
    "* Part 8.2: Building Ensembles with Scikit-Learn and Keras [[Video]](https://www.youtube.com/watch?v=LQ-9ZRBLasw&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](t81_558_class_08_2_keras_ensembles.ipynb)\n",
    "* Part 8.3: How Should you Architect Your Keras Neural Network: Hyperparameters [[Video]](https://www.youtube.com/watch?v=1q9klwSoUQw&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](t81_558_class_08_3_keras_hyperparameters.ipynb)\n",
    "* **Part 8.4: Bayesian Hyperparameter Optimization for Keras** [[Video]](https://www.youtube.com/watch?v=sXdxyUCCm8s&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](t81_558_class_08_4_bayesian_hyperparameter_opt.ipynb)\n",
    "* Part 8.5: Current Semester's Kaggle [[Video]](https://www.youtube.com/watch?v=48OrNYYey5E) [[Notebook]](t81_558_class_08_5_kaggle_project.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 8.4: Bayesian Hyperparameter Optimization for Keras\n",
    "\n",
    "Snoek, J., Larochelle, H., & Adams, R. P. (2012). [Practical bayesian optimization of machine learning algorithms](https://arxiv.org/pdf/1206.2944.pdf). In *Advances in neural information processing systems* (pp. 2951-2959).\n",
    "\n",
    "\n",
    "* [bayesian-optimization](https://github.com/fmfn/BayesianOptimization)\n",
    "* [hyperopt](https://github.com/hyperopt/hyperopt)\n",
    "* [spearmint](https://github.com/JasperSnoek/spearmint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore useless W0819 warnings generated by TensorFlow 2.0.  Hopefully can remove this ignore in the future.\n",
    "# See https://github.com/tensorflow/tensorflow/issues/31308\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generate dummies for job\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for area\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Missing values for income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standardize ranges\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['age'] = zscore(df['age'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('product').drop('id')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['product']) # Classification\n",
    "products = dummies.columns\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7058934066677466\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.keras.initializers\n",
    "import statistics\n",
    "import tensorflow.keras\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_network(dropout,lr,neuronPct,neuronShrink):\n",
    "    SPLITS = 2\n",
    "\n",
    "    # Bootstrap\n",
    "    boot = StratifiedShuffleSplit(n_splits=SPLITS, test_size=0.1)\n",
    "\n",
    "    # Track progress\n",
    "    mean_benchmark = []\n",
    "    epochs_needed = []\n",
    "    num = 0\n",
    "    neuronCount = int(neuronPct * 5000)\n",
    "\n",
    "    # Loop through samples\n",
    "    for train, test in boot.split(x,df['product']):\n",
    "        start_time = time.time()\n",
    "        num+=1\n",
    "\n",
    "        # Split train and test\n",
    "        x_train = x[train]\n",
    "        y_train = y[train]\n",
    "        x_test = x[test]\n",
    "        y_test = y[test]\n",
    "\n",
    "        # Construct neural network\n",
    "        # kernel_initializer = tensorflow.keras.initializers.he_uniform(seed=None)\n",
    "        model = Sequential()\n",
    "        \n",
    "        layer = 0\n",
    "        while neuronCount>25 and layer<10:\n",
    "            #print(neuronCount)\n",
    "            if layer==0:\n",
    "                model.add(Dense(neuronCount, \n",
    "                    input_dim=x.shape[1], \n",
    "                    activation=PReLU())) \n",
    "            else:\n",
    "                model.add(Dense(neuronCount, activation=PReLU())) \n",
    "            model.add(Dropout(dropout))\n",
    "        \n",
    "            neuronCount = neuronCount * neuronShrink\n",
    "        \n",
    "        model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lr))\n",
    "        monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "            patience=100, verbose=0, mode='auto', restore_best_weights=True)\n",
    "\n",
    "        # Train on the bootstrap sample\n",
    "        model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=0,epochs=1000)\n",
    "        epochs = monitor.stopped_epoch\n",
    "        epochs_needed.append(epochs)\n",
    "\n",
    "        # Predict on the out of boot (validation)\n",
    "        pred = model.predict(x_test)\n",
    "\n",
    "        # Measure this bootstrap's log loss\n",
    "        y_compare = np.argmax(y_test,axis=1) # For log loss calculation\n",
    "        score = metrics.log_loss(y_compare, pred)\n",
    "        mean_benchmark.append(score)\n",
    "        m1 = statistics.mean(mean_benchmark)\n",
    "        m2 = statistics.mean(epochs_needed)\n",
    "        mdev = statistics.pstdev(mean_benchmark)\n",
    "\n",
    "        # Record this iteration\n",
    "        time_took = time.time() - start_time\n",
    "        #print(f\"#{num}: score={score:.6f}, mean score={m1:.6f}, stdev={mdev:.6f}, epochs={epochs}, mean epochs={int(m2)}, time={hms_string(time_took)}\")\n",
    "\n",
    "    tensorflow.keras.backend.clear_session()\n",
    "    return (-m1)\n",
    "\n",
    "print(evaluate_network(\n",
    "    dropout=0.2,\n",
    "    lr=1e-3,\n",
    "    neuronPct=0.2,\n",
    "    neuronShrink=0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |  dropout  |    lr     | neuronPct | neuron... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.808   \u001b[0m | \u001b[0m 0.2081  \u001b[0m | \u001b[0m 0.07203 \u001b[0m | \u001b[0m 0.01011 \u001b[0m | \u001b[0m 0.3093  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.749   \u001b[0m | \u001b[95m 0.07323 \u001b[0m | \u001b[95m 0.009234\u001b[0m | \u001b[95m 0.1944  \u001b[0m | \u001b[95m 0.3521  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-4.247   \u001b[0m | \u001b[0m 0.198   \u001b[0m | \u001b[0m 0.05388 \u001b[0m | \u001b[0m 0.425   \u001b[0m | \u001b[0m 0.6884  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.7721  \u001b[0m | \u001b[0m 0.102   \u001b[0m | \u001b[0m 0.08781 \u001b[0m | \u001b[0m 0.03711 \u001b[0m | \u001b[0m 0.6738  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.7539  \u001b[0m | \u001b[0m 0.2082  \u001b[0m | \u001b[0m 0.05587 \u001b[0m | \u001b[0m 0.149   \u001b[0m | \u001b[0m 0.2061  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-9.42    \u001b[0m | \u001b[0m 0.3996  \u001b[0m | \u001b[0m 0.09683 \u001b[0m | \u001b[0m 0.3203  \u001b[0m | \u001b[0m 0.6954  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-2.792   \u001b[0m | \u001b[0m 0.4373  \u001b[0m | \u001b[0m 0.08946 \u001b[0m | \u001b[0m 0.09419 \u001b[0m | \u001b[0m 0.04866 \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-0.6323  \u001b[0m | \u001b[95m 0.08475 \u001b[0m | \u001b[95m 0.08781 \u001b[0m | \u001b[95m 0.1074  \u001b[0m | \u001b[95m 0.4269  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.9107  \u001b[0m | \u001b[0m 0.478   \u001b[0m | \u001b[0m 0.05332 \u001b[0m | \u001b[0m 0.695   \u001b[0m | \u001b[0m 0.3224  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m 0.3426  \u001b[0m | \u001b[0m 0.08346 \u001b[0m | \u001b[0m 0.02811 \u001b[0m | \u001b[0m 0.7526  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.7533  \u001b[0m | \u001b[0m 0.07983 \u001b[0m | \u001b[0m 0.09366 \u001b[0m | \u001b[0m 0.09413 \u001b[0m | \u001b[0m 0.2711  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-4.791   \u001b[0m | \u001b[0m 0.1455  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.5106  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.697   \u001b[0m | \u001b[0m 0.1572  \u001b[0m | \u001b[0m 0.08427 \u001b[0m | \u001b[0m 0.1384  \u001b[0m | \u001b[0m 0.3317  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.8146  \u001b[0m | \u001b[0m 0.1625  \u001b[0m | \u001b[0m 0.09092 \u001b[0m | \u001b[0m 0.141   \u001b[0m | \u001b[0m 0.3304  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-3.865   \u001b[0m | \u001b[0m 0.1465  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.08814 \u001b[0m | \u001b[0m 0.2638  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.7489  \u001b[0m | \u001b[0m 0.0861  \u001b[0m | \u001b[0m 0.08133 \u001b[0m | \u001b[0m 0.1369  \u001b[0m | \u001b[0m 0.3567  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.7244  \u001b[0m | \u001b[0m 0.1248  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.07736 \u001b[0m | \u001b[0m 0.3517  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.8222  \u001b[0m | \u001b[0m 0.1298  \u001b[0m | \u001b[0m 0.055   \u001b[0m | \u001b[0m 0.1601  \u001b[0m | \u001b[0m 0.4019  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.7267  \u001b[0m | \u001b[0m 0.1011  \u001b[0m | \u001b[0m 0.09548 \u001b[0m | \u001b[0m 0.1783  \u001b[0m | \u001b[0m 0.2785  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.7009  \u001b[0m | \u001b[0m 0.1294  \u001b[0m | \u001b[0m 0.05607 \u001b[0m | \u001b[0m 0.2289  \u001b[0m | \u001b[0m 0.3341  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.7573  \u001b[0m | \u001b[0m 0.1849  \u001b[0m | \u001b[0m 0.0937  \u001b[0m | \u001b[0m 0.2199  \u001b[0m | \u001b[0m 0.2188  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-1.431   \u001b[0m | \u001b[0m 0.1691  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1641  \u001b[0m | \u001b[0m 0.1444  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.7638  \u001b[0m | \u001b[0m 0.2761  \u001b[0m | \u001b[0m 0.0953  \u001b[0m | \u001b[0m 0.1813  \u001b[0m | \u001b[0m 0.2216  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.6803  \u001b[0m | \u001b[0m 0.2492  \u001b[0m | \u001b[0m 0.01952 \u001b[0m | \u001b[0m 0.2328  \u001b[0m | \u001b[0m 0.1984  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.8446  \u001b[0m | \u001b[0m 0.2441  \u001b[0m | \u001b[0m 0.03696 \u001b[0m | \u001b[0m 0.242   \u001b[0m | \u001b[0m 0.2956  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-7.458   \u001b[0m | \u001b[0m 0.02494 \u001b[0m | \u001b[0m 0.08676 \u001b[0m | \u001b[0m 0.2025  \u001b[0m | \u001b[0m 0.4408  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.805   \u001b[0m | \u001b[0m 0.2273  \u001b[0m | \u001b[0m 0.0532  \u001b[0m | \u001b[0m 0.1991  \u001b[0m | \u001b[0m 0.2466  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.7647  \u001b[0m | \u001b[0m 0.1413  \u001b[0m | \u001b[0m 0.09734 \u001b[0m | \u001b[0m 0.1076  \u001b[0m | \u001b[0m 0.4065  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.8192  \u001b[0m | \u001b[0m 0.1045  \u001b[0m | \u001b[0m 0.04512 \u001b[0m | \u001b[0m 0.09526 \u001b[0m | \u001b[0m 0.3872  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.6994  \u001b[0m | \u001b[0m 0.1452  \u001b[0m | \u001b[0m 0.01052 \u001b[0m | \u001b[0m 0.1872  \u001b[0m | \u001b[0m 0.3474  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-0.8818  \u001b[0m | \u001b[0m 0.1516  \u001b[0m | \u001b[0m 0.02732 \u001b[0m | \u001b[0m 0.2418  \u001b[0m | \u001b[0m 0.2627  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-0.8408  \u001b[0m | \u001b[0m 0.2574  \u001b[0m | \u001b[0m 0.08469 \u001b[0m | \u001b[0m 0.2706  \u001b[0m | \u001b[0m 0.2232  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-0.9713  \u001b[0m | \u001b[0m 0.2529  \u001b[0m | \u001b[0m 0.07345 \u001b[0m | \u001b[0m 0.2053  \u001b[0m | \u001b[0m 0.155   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-0.8179  \u001b[0m | \u001b[0m 0.0589  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.04945 \u001b[0m | \u001b[0m 0.3889  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-0.6717  \u001b[0m | \u001b[0m 0.06453 \u001b[0m | \u001b[0m 0.01714 \u001b[0m | \u001b[0m 0.2199  \u001b[0m | \u001b[0m 0.2782  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-0.7832  \u001b[0m | \u001b[0m 0.33    \u001b[0m | \u001b[0m 0.02886 \u001b[0m | \u001b[0m 0.2287  \u001b[0m | \u001b[0m 0.238   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-0.7605  \u001b[0m | \u001b[0m 0.2989  \u001b[0m | \u001b[0m 0.01298 \u001b[0m | \u001b[0m 0.1508  \u001b[0m | \u001b[0m 0.1953  \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-0.9122  \u001b[0m | \u001b[0m 0.2796  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.07043 \u001b[0m | \u001b[0m 0.2524  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-0.7019  \u001b[0m | \u001b[0m 0.327   \u001b[0m | \u001b[0m 0.04404 \u001b[0m | \u001b[0m 0.1438  \u001b[0m | \u001b[0m 0.2958  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-0.9592  \u001b[0m | \u001b[0m 0.2978  \u001b[0m | \u001b[0m 0.08525 \u001b[0m | \u001b[0m 0.04401 \u001b[0m | \u001b[0m 0.3497  \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-0.9438  \u001b[0m | \u001b[0m 0.3331  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.2227  \u001b[0m | \u001b[0m 0.3234  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-1.061   \u001b[0m | \u001b[0m 0.3862  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1474  \u001b[0m | \u001b[0m 0.2473  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-0.8119  \u001b[0m | \u001b[0m 0.1738  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.03256 \u001b[0m | \u001b[0m 0.7485  \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-0.7319  \u001b[0m | \u001b[0m 0.06608 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.03604 \u001b[0m | \u001b[0m 0.768   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-9.313   \u001b[0m | \u001b[0m 0.1106  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1221  \u001b[0m | \u001b[0m 0.7358  \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-0.685   \u001b[0m | \u001b[0m 0.1036  \u001b[0m | \u001b[0m 0.04207 \u001b[0m | \u001b[0m 0.1792  \u001b[0m | \u001b[0m 0.3113  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-0.6849  \u001b[0m | \u001b[0m 0.29    \u001b[0m | \u001b[0m 0.03289 \u001b[0m | \u001b[0m 0.1786  \u001b[0m | \u001b[0m 0.2545  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-0.6742  \u001b[0m | \u001b[0m 0.05611 \u001b[0m | \u001b[0m 0.08651 \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.715   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-0.791   \u001b[0m | \u001b[0m 0.2815  \u001b[0m | \u001b[0m 0.09847 \u001b[0m | \u001b[0m 0.1471  \u001b[0m | \u001b[0m 0.2964  \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-0.7455  \u001b[0m | \u001b[0m 0.01881 \u001b[0m | \u001b[0m 0.09454 \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.7835  \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-0.7938  \u001b[0m | \u001b[0m 0.1602  \u001b[0m | \u001b[0m 0.08336 \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.687   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-0.6579  \u001b[0m | \u001b[0m 0.0813  \u001b[0m | \u001b[0m 0.05389 \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.7823  \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m-0.8132  \u001b[0m | \u001b[0m 0.2375  \u001b[0m | \u001b[0m 0.08941 \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.7452  \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m-0.8451  \u001b[0m | \u001b[0m 0.0796  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.8295  \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m-4.495   \u001b[0m | \u001b[0m 0.1022  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.2622  \u001b[0m | \u001b[0m 0.3227  \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m-0.6982  \u001b[0m | \u001b[0m 0.1664  \u001b[0m | \u001b[0m 0.07297 \u001b[0m | \u001b[0m 0.2062  \u001b[0m | \u001b[0m 0.2991  \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m-0.7454  \u001b[0m | \u001b[0m 0.03926 \u001b[0m | \u001b[0m 0.04448 \u001b[0m | \u001b[0m 0.1753  \u001b[0m | \u001b[0m 0.2805  \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m-0.8045  \u001b[0m | \u001b[0m 0.0906  \u001b[0m | \u001b[0m 0.05141 \u001b[0m | \u001b[0m 0.2087  \u001b[0m | \u001b[0m 0.2327  \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m-0.7409  \u001b[0m | \u001b[0m 0.1745  \u001b[0m | \u001b[0m 0.06441 \u001b[0m | \u001b[0m 0.1988  \u001b[0m | \u001b[0m 0.3648  \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m-0.8748  \u001b[0m | \u001b[0m 0.3147  \u001b[0m | \u001b[0m 0.06653 \u001b[0m | \u001b[0m 0.1249  \u001b[0m | \u001b[0m 0.2325  \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m-0.7992  \u001b[0m | \u001b[0m 0.1762  \u001b[0m | \u001b[0m 0.02651 \u001b[0m | \u001b[0m 0.223   \u001b[0m | \u001b[0m 0.1941  \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m-0.9095  \u001b[0m | \u001b[0m 0.1992  \u001b[0m | \u001b[0m 0.04554 \u001b[0m | \u001b[0m 0.2805  \u001b[0m | \u001b[0m 0.228   \u001b[0m |\n",
      "| \u001b[95m 63      \u001b[0m | \u001b[95m-0.6265  \u001b[0m | \u001b[95m 0.02562 \u001b[0m | \u001b[95m 0.001397\u001b[0m | \u001b[95m 0.2067  \u001b[0m | \u001b[95m 0.2313  \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m-1.221   \u001b[0m | \u001b[0m 0.02065 \u001b[0m | \u001b[0m 0.06082 \u001b[0m | \u001b[0m 0.2361  \u001b[0m | \u001b[0m 0.2467  \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m-0.7211  \u001b[0m | \u001b[0m 0.09761 \u001b[0m | \u001b[0m 0.032   \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.6865  \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m-0.7193  \u001b[0m | \u001b[0m 0.175   \u001b[0m | \u001b[0m 0.03719 \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.7573  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 67      \u001b[0m | \u001b[0m-0.7689  \u001b[0m | \u001b[0m 0.1873  \u001b[0m | \u001b[0m 0.08987 \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.8128  \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m-0.8077  \u001b[0m | \u001b[0m 0.06132 \u001b[0m | \u001b[0m 0.08523 \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.6346  \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m-0.722   \u001b[0m | \u001b[0m 0.2708  \u001b[0m | \u001b[0m 0.03508 \u001b[0m | \u001b[0m 0.1714  \u001b[0m | \u001b[0m 0.351   \u001b[0m |\n",
      "| \u001b[95m 70      \u001b[0m | \u001b[95m-0.625   \u001b[0m | \u001b[95m 0.3273  \u001b[0m | \u001b[95m 0.004525\u001b[0m | \u001b[95m 0.2153  \u001b[0m | \u001b[95m 0.3222  \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m-0.924   \u001b[0m | \u001b[0m 0.3518  \u001b[0m | \u001b[0m 0.04172 \u001b[0m | \u001b[0m 0.1687  \u001b[0m | \u001b[0m 0.3738  \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m-1.955   \u001b[0m | \u001b[0m 0.3863  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1799  \u001b[0m | \u001b[0m 0.2775  \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m-0.7582  \u001b[0m | \u001b[0m 0.2965  \u001b[0m | \u001b[0m 0.03273 \u001b[0m | \u001b[0m 0.2483  \u001b[0m | \u001b[0m 0.3761  \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m-0.8827  \u001b[0m | \u001b[0m 0.3177  \u001b[0m | \u001b[0m 0.03126 \u001b[0m | \u001b[0m 0.2904  \u001b[0m | \u001b[0m 0.3001  \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m-4.583   \u001b[0m | \u001b[0m 0.2941  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.3021  \u001b[0m | \u001b[0m 0.2117  \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m-0.8305  \u001b[0m | \u001b[0m 0.2995  \u001b[0m | \u001b[0m 0.07527 \u001b[0m | \u001b[0m 0.2263  \u001b[0m | \u001b[0m 0.2727  \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m-4.336   \u001b[0m | \u001b[0m 0.2343  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.177   \u001b[0m | \u001b[0m 0.1717  \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m-0.7448  \u001b[0m | \u001b[0m 0.1237  \u001b[0m | \u001b[0m 0.0939  \u001b[0m | \u001b[0m 0.1882  \u001b[0m | \u001b[0m 0.3495  \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m-0.8684  \u001b[0m | \u001b[0m 0.326   \u001b[0m | \u001b[0m 0.05626 \u001b[0m | \u001b[0m 0.1872  \u001b[0m | \u001b[0m 0.1989  \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m-0.9153  \u001b[0m | \u001b[0m 0.2212  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1378  \u001b[0m | \u001b[0m 0.2409  \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m-1.057   \u001b[0m | \u001b[0m 0.08076 \u001b[0m | \u001b[0m 0.09037 \u001b[0m | \u001b[0m 0.09694 \u001b[0m | \u001b[0m 0.2686  \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m-0.704   \u001b[0m | \u001b[0m 0.06511 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.07069 \u001b[0m | \u001b[0m 0.3129  \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m-0.8932  \u001b[0m | \u001b[0m 0.2993  \u001b[0m | \u001b[0m 0.04966 \u001b[0m | \u001b[0m 0.207   \u001b[0m | \u001b[0m 0.3244  \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m-0.7965  \u001b[0m | \u001b[0m 0.2252  \u001b[0m | \u001b[0m 0.06564 \u001b[0m | \u001b[0m 0.2396  \u001b[0m | \u001b[0m 0.1955  \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m-0.7928  \u001b[0m | \u001b[0m 0.08042 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.04227 \u001b[0m | \u001b[0m 0.2672  \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m-0.7558  \u001b[0m | \u001b[0m 0.2734  \u001b[0m | \u001b[0m 0.04656 \u001b[0m | \u001b[0m 0.1046  \u001b[0m | \u001b[0m 0.3102  \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m-0.7425  \u001b[0m | \u001b[0m 0.1174  \u001b[0m | \u001b[0m 0.07486 \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.7368  \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m-0.7796  \u001b[0m | \u001b[0m 0.1937  \u001b[0m | \u001b[0m 0.03761 \u001b[0m | \u001b[0m 0.1358  \u001b[0m | \u001b[0m 0.3724  \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m-0.8132  \u001b[0m | \u001b[0m 0.1264  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.2416  \u001b[0m | \u001b[0m 0.2696  \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m-0.8748  \u001b[0m | \u001b[0m 0.3605  \u001b[0m | \u001b[0m 0.03375 \u001b[0m | \u001b[0m 0.261   \u001b[0m | \u001b[0m 0.3505  \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m-0.8653  \u001b[0m | \u001b[0m 0.2204  \u001b[0m | \u001b[0m 0.09076 \u001b[0m | \u001b[0m 0.07602 \u001b[0m | \u001b[0m 0.3493  \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m-0.7993  \u001b[0m | \u001b[0m 0.2924  \u001b[0m | \u001b[0m 0.08392 \u001b[0m | \u001b[0m 0.1251  \u001b[0m | \u001b[0m 0.3694  \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m-0.7743  \u001b[0m | \u001b[0m 0.02192 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.07835 \u001b[0m | \u001b[0m 0.2687  \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m-3.379   \u001b[0m | \u001b[0m 0.006269\u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1935  \u001b[0m | \u001b[0m 0.2977  \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m-4.511   \u001b[0m | \u001b[0m 0.07035 \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.2298  \u001b[0m | \u001b[0m 0.2072  \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m-0.7522  \u001b[0m | \u001b[0m 0.07479 \u001b[0m | \u001b[0m 0.0646  \u001b[0m | \u001b[0m 0.2103  \u001b[0m | \u001b[0m 0.2803  \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m-0.75    \u001b[0m | \u001b[0m 0.1449  \u001b[0m | \u001b[0m 0.06419 \u001b[0m | \u001b[0m 0.1969  \u001b[0m | \u001b[0m 0.2445  \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m-0.8035  \u001b[0m | \u001b[0m 0.1292  \u001b[0m | \u001b[0m 0.04167 \u001b[0m | \u001b[0m 0.1471  \u001b[0m | \u001b[0m 0.3554  \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m-0.7776  \u001b[0m | \u001b[0m 0.2769  \u001b[0m | \u001b[0m 0.05528 \u001b[0m | \u001b[0m 0.221   \u001b[0m | \u001b[0m 0.2198  \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m-0.8095  \u001b[0m | \u001b[0m 0.2271  \u001b[0m | \u001b[0m 0.05578 \u001b[0m | \u001b[0m 0.1619  \u001b[0m | \u001b[0m 0.313   \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m-0.8007  \u001b[0m | \u001b[0m 0.2055  \u001b[0m | \u001b[0m 0.08776 \u001b[0m | \u001b[0m 0.2506  \u001b[0m | \u001b[0m 0.2714  \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m-2.388   \u001b[0m | \u001b[0m 0.2859  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1593  \u001b[0m | \u001b[0m 0.3068  \u001b[0m |\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m-0.9203  \u001b[0m | \u001b[0m 0.3229  \u001b[0m | \u001b[0m 0.0838  \u001b[0m | \u001b[0m 0.1025  \u001b[0m | \u001b[0m 0.309   \u001b[0m |\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m-0.8051  \u001b[0m | \u001b[0m 0.2405  \u001b[0m | \u001b[0m 0.0805  \u001b[0m | \u001b[0m 0.1658  \u001b[0m | \u001b[0m 0.3696  \u001b[0m |\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m-1.095   \u001b[0m | \u001b[0m 0.3303  \u001b[0m | \u001b[0m 0.07645 \u001b[0m | \u001b[0m 0.1778  \u001b[0m | \u001b[0m 0.2638  \u001b[0m |\n",
      "| \u001b[0m 106     \u001b[0m | \u001b[0m-0.8946  \u001b[0m | \u001b[0m 0.2325  \u001b[0m | \u001b[0m 0.03541 \u001b[0m | \u001b[0m 0.217   \u001b[0m | \u001b[0m 0.3639  \u001b[0m |\n",
      "| \u001b[0m 107     \u001b[0m | \u001b[0m-0.747   \u001b[0m | \u001b[0m 0.01424 \u001b[0m | \u001b[0m 0.03654 \u001b[0m | \u001b[0m 0.1713  \u001b[0m | \u001b[0m 0.2216  \u001b[0m |\n",
      "| \u001b[0m 108     \u001b[0m | \u001b[0m-0.9091  \u001b[0m | \u001b[0m 0.294   \u001b[0m | \u001b[0m 0.06203 \u001b[0m | \u001b[0m 0.1916  \u001b[0m | \u001b[0m 0.3966  \u001b[0m |\n",
      "| \u001b[0m 109     \u001b[0m | \u001b[0m-0.8175  \u001b[0m | \u001b[0m 0.04648 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1281  \u001b[0m | \u001b[0m 0.3062  \u001b[0m |\n",
      "| \u001b[0m 110     \u001b[0m | \u001b[0m-0.6854  \u001b[0m | \u001b[0m 0.03557 \u001b[0m | \u001b[0m 0.03666 \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.7439  \u001b[0m |\n",
      "=========================================================================\n",
      "{'target': -0.6249607861566802, 'params': {'dropout': 0.32725824337964265, 'lr': 0.004524867013084486, 'neuronPct': 0.21533878079295526, 'neuronShrink': 0.3222074238250132}}\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "import time\n",
    "\n",
    "# Supress NaN warnings, see: https://stackoverflow.com/questions/34955158/what-might-be-the-cause-of-invalid-value-encountered-in-less-equal-in-numpy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category =RuntimeWarning)\n",
    "\n",
    "# Bounded region of parameter space\n",
    "pbounds = {'dropout': (0.0, 0.499),\n",
    "           'lr': (0.0, 0.1),\n",
    "           'neuronPct': (0.01, 1),\n",
    "           'neuronShrink': (0.01, 1)\n",
    "          }\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=evaluate_network,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "optimizer.maximize(init_points=10, n_iter=100,)\n",
    "time_took = time.time() - start_time\n",
    "\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'target': -0.5995399297989206, 'params': {'dropout': 0.13361186083708476, 'lr': 0.014767159034158229, 'neuronPct': 0.01100802893634497, 'neuronShrink': 0.7109218810227248}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
