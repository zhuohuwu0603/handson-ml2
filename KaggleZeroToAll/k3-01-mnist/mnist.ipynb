{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Digit Recognizer\n",
    "## Learn computer vision fundamentals with the famous MNIST data\n",
    "Link: https://www.kaggle.com/c/digit-recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Problem/data description\n",
    "### Problem\n",
    "The goal in this competition is to take an image of a handwritten single digit, and determine what that digit is. As the competition progresses, we will release tutorials which explain different machine learning algorithms and help you to get started.\n",
    "\n",
    "### Data Description\n",
    "The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\n",
    "\n",
    "For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below.\n",
    "\n",
    "Visually, if we omit the \"pixel\" prefix, the pixels make up the image like this:\n",
    "```\n",
    "000 001 002 003 ... 026 027\n",
    "028 029 030 031 ... 054 055\n",
    "056 057 058 059 ... 082 083\n",
    " |   |   |   |  ...  |   |\n",
    "728 729 730 731 ... 754 755\n",
    "756 757 758 759 ... 782 783 \n",
    "```\n",
    "The test data set, (test.csv), is the same as the training set, except that it does not contain the \"label\" column.\n",
    "\n",
    "Your submission file should be in the following format: For each of the 28000 images in the test set, output a single line with the digit you predict. For example, if you predict that the first image is of a 3, the second image is of a 7, and the third image is of a 8, then your submission file would look like:\n",
    "```\n",
    "3\n",
    "7\n",
    "8\n",
    "(27997 more lines)\n",
    "```\n",
    "\n",
    "The evaluation metric for this contest is the categorization accuracy, or the proportion of test images that are correctly classified. For example, a categorization accuracy of 0.97 indicates that you have correctly classified all but 3% of the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Libraries and settings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "LEARNING_RATE = 0.001\n",
    "TRAINING_STEPS = 3000\n",
    "BATCH_SIZE = 100\n",
    "DISPLAY_STEP = 10\n",
    "DROPOUT_CONV = 0.8\n",
    "DROPOUT_HIDDEN = 0.6\n",
    "VALIDATION_SIZE = 2000      # Set to 0 to train on all available data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place the 'train.csv' and 'test.csv' into sub folder named with 'input'. To start, we read given train and test data from each csv file. At first we read train.csv file.\n",
    "Read MNIST data set (Train data from CSV file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./input/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains label and written images for number. `[label pixel_0, pixel_1, ... , pixel_784]`\n",
    "So, we split data into label and image from each row.\n",
    "Extracting images and labels from given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For images\n",
    "images = data.iloc[:,1:].values\n",
    "images = images.astype(np.float)\n",
    "\n",
    "# For labels\n",
    "labels_flat = data[[0]].values.ravel()\n",
    "labels_count = np.unique(labels_flat).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For easy implementation of output layer, we convert label with number into ont-hot-vector.\n",
    "You can refer the idea of one-hot on this [link](https://en.wikipedia.org/wiki/One-hot).\n",
    "For example, we convert the numbers as follow: \n",
    "\n",
    "`0:[1 0 0 0 0 0 0 0 0 0]`\n",
    "\n",
    "`1:[0 1 0 0 0 0 0 0 0 0]`\n",
    "\n",
    " ...\n",
    " \n",
    "`9:[0 0 0 0 0 0 0 0 0 1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = dense_to_one_hot(labels_flat, labels_count)\n",
    "labels = labels.astype(np.uint8)\n",
    "\n",
    "# Then we normalize the intensity of each pixel from [0:255] into [0.0:1:0]\n",
    "images = np.multiply(images, 1.0 / 255.0)\n",
    "image_size = images.shape[1]\n",
    "image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Serve data by batches\n",
    "def next_batch(batch_size):    \n",
    "    global train_images\n",
    "    global train_labels\n",
    "    global index_in_epoch\n",
    "    global epochs_completed\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    # when all trainig data have been already used, it is reorder randomly    \n",
    "    if index_in_epoch > num_examples:\n",
    "        # finished epoch\n",
    "        epochs_completed += 1\n",
    "        # shuffle the data\n",
    "        perm = np.arange(num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        train_images = train_images[perm]\n",
    "        train_labels = train_labels[perm]\n",
    "        # start next epoch\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "        assert batch_size <= num_examples\n",
    "    end = index_in_epoch\n",
    "    return train_images[start:end], train_labels[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying our trained model to test data, we validate our trained model using validation dataset.\n",
    "So, we split training data into [train, validation].\n",
    "Split data into training & validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_images = images[:VALIDATION_SIZE]\n",
    "validation_labels = labels[:VALIDATION_SIZE]\n",
    "\n",
    "train_images = images[VALIDATION_SIZE:]\n",
    "train_labels = labels[VALIDATION_SIZE:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. Model\n",
    "We start creating cnn model with definition of input and output.\n",
    "This model handle each image and make decision for the image with digit classes [0-9]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Input and Output\n",
    "X = tf.placeholder('float', shape=[None, image_size])       # mnist data image of shape 28*28=784\n",
    "Y_gt = tf.placeholder('float', shape=[None, labels_count])    # 0-9 digits recognition => 10 classes\n",
    "drop_conv = tf.placeholder('float')\n",
    "drop_hidden = tf.placeholder('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using below functions, we can generate weight and bias easily.\n",
    "Basically, the simple weight and bias are generated on normal distribution.\n",
    "For better result, we implemented Xavier's initialization with input and output connections.\n",
    "For the detail explanation, you can refer two blogs: [deepdish](http://deepdish.io/2015/02/24/network-initialization/) and [andyljones](http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Weight initialization\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# Weight initialization (Xavier's init)\n",
    "def weight_xavier_init(n_inputs, n_outputs, uniform=True):\n",
    "    if uniform:\n",
    "        init_range = tf.sqrt(6.0 / (n_inputs + n_outputs))\n",
    "        return tf.random_uniform_initializer(-init_range, init_range)\n",
    "    else:\n",
    "        stddev = tf.sqrt(3.0 / (n_inputs + n_outputs))\n",
    "        return tf.truncated_normal_initializer(stddev=stddev)\n",
    "\n",
    "# Bias initialization\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# 2D convolution\n",
    "def conv2d(X, W):\n",
    "    return tf.nn.conv2d(X, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# Max Pooling\n",
    "def max_pool_2x2(X):\n",
    "    return tf.nn.max_pool(X, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using above functions, we make two convolutional layers, and two fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "W1 = tf.get_variable(\"W1\", shape=[5, 5, 1, 32], initializer=weight_xavier_init(5*5*1, 32))\n",
    "W2 = tf.get_variable(\"W2\", shape=[5, 5, 32, 64], initializer=weight_xavier_init(5*5*32, 64))\n",
    "W3_FC1 = tf.get_variable(\"W3_FC1\", shape=[64*7*7, 1024], initializer=weight_xavier_init(64*7*7, 1024))\n",
    "W4_FC2 = tf.get_variable(\"W4_FC2\", shape=[1024, labels_count], initializer=weight_xavier_init(1024, labels_count))\n",
    "\n",
    "B1 = bias_variable([32])\n",
    "B2 = bias_variable([64])\n",
    "B3_FC1 = bias_variable([1024])\n",
    "B4_FC2 = bias_variable([labels_count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we transform from 1D input vector into 2D image. \n",
    "For the convolutional layer, we apply three steps:\n",
    "\n",
    "1. Convolution\n",
    "1. Max-pooling\n",
    "1. Dropout\n",
    "\n",
    "For the fully connected layer, the process is same with basic neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CNN model\n",
    "X1 = tf.reshape(X, [-1,image_width , image_height,1])                   # shape=(?, 28, 28, 1)\n",
    "    \n",
    "# Layer 1\n",
    "l1_conv = tf.nn.relu(conv2d(X1, W1) + B1)                               # shape=(?, 28, 28, 32)\n",
    "l1_pool = max_pool_2x2(l1_conv)                                         # shape=(?, 14, 14, 32)\n",
    "l1_drop = tf.nn.dropout(l1_pool, drop_conv)\n",
    "\n",
    "# Layer 2\n",
    "l2_conv = tf.nn.relu(conv2d(l1_drop, W2)+ B2)                           # shape=(?, 14, 14, 64)\n",
    "l2_pool = max_pool_2x2(l2_conv)                                         # shape=(?, 7, 7, 64)\n",
    "l2_drop = tf.nn.dropout(l2_pool, drop_conv) \n",
    "\n",
    "# Layer 3 - FC1\n",
    "l3_flat = tf.reshape(l2_drop, [-1, W3_FC1.get_shape().as_list()[0]])    # shape=(?, 1024)\n",
    "l3_feed = tf.nn.relu(tf.matmul(l3_flat, W3_FC1)+ B3_FC1) \n",
    "l3_drop = tf.nn.dropout(l3_feed, drop_hidden)\n",
    "\n",
    "# Layer 4 - FC2\n",
    "Y_pred = tf.nn.softmax(tf.matmul(l3_drop, W4_FC2)+ B4_FC2)              # shape=(?, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined cross-entropy for the cost function with L2-regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cost function and training \n",
    "cost = -tf.reduce_sum(Y_gt*tf.log(Y_pred))\n",
    "regularizer = (tf.nn.l2_loss(W3_FC1) + tf.nn.l2_loss(B3_FC1) + tf.nn.l2_loss(W4_FC2) + tf.nn.l2_loss(B4_FC2))\n",
    "cost += 5e-4 * regularizer\n",
    "\n",
    "#train_op = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cost)\n",
    "train_op = tf.train.RMSPropOptimizer(LEARNING_RATE, 0.9).minimize(cost)\n",
    "correct_predict = tf.equal(tf.argmax(Y_pred, 1), tf.argmax(Y_gt, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predict, 'float'))\n",
    "predict = tf.argmax(Y_pred, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow Session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy / validation_accuracy => 0.09 / 0.08 for step 0\n",
      "training_accuracy / validation_accuracy => 0.21 / 0.22 for step 1\n",
      "training_accuracy / validation_accuracy => 0.10 / 0.11 for step 2\n",
      "training_accuracy / validation_accuracy => 0.15 / 0.19 for step 3\n",
      "training_accuracy / validation_accuracy => 0.33 / 0.27 for step 4\n",
      "training_accuracy / validation_accuracy => 0.35 / 0.36 for step 5\n",
      "training_accuracy / validation_accuracy => 0.52 / 0.48 for step 6\n",
      "training_accuracy / validation_accuracy => 0.47 / 0.45 for step 7\n",
      "training_accuracy / validation_accuracy => 0.43 / 0.44 for step 8\n",
      "training_accuracy / validation_accuracy => 0.48 / 0.57 for step 9\n",
      "training_accuracy / validation_accuracy => 0.38 / 0.51 for step 10\n",
      "training_accuracy / validation_accuracy => 0.65 / 0.71 for step 20\n",
      "training_accuracy / validation_accuracy => 0.85 / 0.77 for step 30\n",
      "training_accuracy / validation_accuracy => 0.83 / 0.79 for step 40\n",
      "training_accuracy / validation_accuracy => 0.91 / 0.85 for step 50\n",
      "training_accuracy / validation_accuracy => 0.93 / 0.87 for step 60\n",
      "training_accuracy / validation_accuracy => 0.93 / 0.91 for step 70\n",
      "training_accuracy / validation_accuracy => 0.94 / 0.91 for step 80\n",
      "training_accuracy / validation_accuracy => 0.78 / 0.85 for step 90\n",
      "training_accuracy / validation_accuracy => 0.96 / 0.89 for step 100\n",
      "training_accuracy / validation_accuracy => 0.96 / 0.94 for step 200\n",
      "training_accuracy / validation_accuracy => 0.96 / 0.95 for step 300\n",
      "training_accuracy / validation_accuracy => 0.97 / 0.96 for step 400\n",
      "training_accuracy / validation_accuracy => 0.97 / 0.97 for step 500\n",
      "training_accuracy / validation_accuracy => 0.98 / 0.98 for step 600\n",
      "training_accuracy / validation_accuracy => 0.98 / 0.98 for step 700\n",
      "training_accuracy / validation_accuracy => 1.00 / 0.95 for step 800\n",
      "training_accuracy / validation_accuracy => 0.96 / 0.95 for step 900\n",
      "training_accuracy / validation_accuracy => 0.98 / 0.98 for step 1000\n",
      "training_accuracy / validation_accuracy => 0.99 / 0.98 for step 2000\n",
      "training_accuracy / validation_accuracy => 1.00 / 0.99 for step 2999\n",
      "validation_accuracy => 0.9865\n"
     ]
    }
   ],
   "source": [
    "epochs_completed = 0\n",
    "index_in_epoch = 0\n",
    "num_examples = train_images.shape[0]\n",
    "\n",
    "# start TensorFlow session\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "# visualisation variables\n",
    "train_accuracies = []\n",
    "validation_accuracies = []\n",
    "\n",
    "DISPLAY_STEP=1\n",
    "\n",
    "for i in range(TRAINING_STEPS):\n",
    "\n",
    "    #get new batch\n",
    "    batch_xs, batch_ys = next_batch(BATCH_SIZE)        \n",
    "\n",
    "    # check progress on every 1st,2nd,...,10th,20th,...,100th... step\n",
    "    if i%DISPLAY_STEP == 0 or (i+1) == TRAINING_STEPS:\n",
    "        \n",
    "        train_accuracy = accuracy.eval(session=sess, \n",
    "                                       feed_dict={X:batch_xs, \n",
    "                                                  Y_gt: batch_ys,\n",
    "                                                  drop_conv: DROPOUT_CONV, \n",
    "                                                  drop_hidden: DROPOUT_HIDDEN})       \n",
    "        if(VALIDATION_SIZE):\n",
    "            validation_accuracy = accuracy.eval(session=sess, \n",
    "                                                feed_dict={ X: validation_images[0:BATCH_SIZE], \n",
    "                                                            Y_gt: validation_labels[0:BATCH_SIZE],\n",
    "                                                            drop_conv: DROPOUT_CONV, drop_hidden: DROPOUT_HIDDEN})                                  \n",
    "            print('training_accuracy / validation_accuracy => %.2f / %.2f for step %d'%(train_accuracy, validation_accuracy, i))\n",
    "            \n",
    "            validation_accuracies.append(validation_accuracy)\n",
    "            \n",
    "        else:\n",
    "             print('training_accuracy => %.4f for step %d'%(train_accuracy, i))\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        # increase DISPLAY_STEP\n",
    "        if i%(DISPLAY_STEP*10) == 0 and i:\n",
    "            DISPLAY_STEP *= 10\n",
    "    # train on batch\n",
    "    sess.run(train_op, feed_dict={X: batch_xs, Y_gt: batch_ys, drop_conv: DROPOUT_CONV, drop_hidden: DROPOUT_HIDDEN})\n",
    "\n",
    "\n",
    "# check final accuracy on validation set  \n",
    "if(VALIDATION_SIZE):\n",
    "    validation_accuracy = accuracy.eval(session=sess,\n",
    "                                        feed_dict={X: validation_images, \n",
    "                                                   Y_gt: validation_labels,\n",
    "                                                   drop_conv: DROPOUT_CONV, drop_hidden: DROPOUT_HIDDEN})\n",
    "    print('validation_accuracy => %.4f'%validation_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_images(28000,784)\n",
      "Submission file is generated.\n"
     ]
    }
   ],
   "source": [
    "# read test data from CSV file \n",
    "test_images = pd.read_csv('./input/test.csv').values\n",
    "test_images = test_images.astype(np.float)\n",
    "\n",
    "# convert from [0:255] => [0.0:1.0]\n",
    "test_images = np.multiply(test_images, 1.0 / 255.0)\n",
    "\n",
    "print('test_images({0[0]},{0[1]})'.format(test_images.shape))\n",
    "\n",
    "\n",
    "# predict test set\n",
    "# predicted_lables = predict.eval(feed_dict={X: test_images, keep_prob: 1.0})\n",
    "\n",
    "# using batches is more resource efficient\n",
    "predicted_lables = np.zeros(test_images.shape[0])\n",
    "for i in range(0,test_images.shape[0]//BATCH_SIZE):\n",
    "    predicted_lables[i*BATCH_SIZE : (i+1)*BATCH_SIZE] = predict.eval(session=sess,\n",
    "                                                                     feed_dict={X: test_images[i*BATCH_SIZE : (i+1)*BATCH_SIZE], drop_conv: 1.0, drop_hidden: 1.0})\n",
    "\n",
    "\n",
    "# save results\n",
    "np.savetxt('submission.csv', \n",
    "           np.c_[range(1,len(test_images)+1),predicted_lables], \n",
    "           delimiter=',', \n",
    "           header = 'ImageId,Label', \n",
    "           comments = '', \n",
    "           fmt='%d')\n",
    "print(\"Submission file is generated.\")\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final submission file is generated on the main directory. You can submit the file into [kaggle evaluation](https://www.kaggle.com/c/digit-recognizer/submit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 5. Future work/exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Try to Modify model for better score on test dataset.\n",
    "* This model is written by TensorFlow v0.9. Welcome Pull Request for better codes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
